## A PyTorch implementation of PPO on CartPole-v1

See latest experiments on [wandb](https://wandb.ai/harshraj22/ppo-Enhanced-CartPole-v1)

Run using `python3 ppo.py` after installing the dependencies.

![image](https://user-images.githubusercontent.com/46635452/148689012-2a40fa9c-63e6-4253-a630-6b7422684f99.png)
