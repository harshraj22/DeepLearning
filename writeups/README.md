# Index <a name='index'></a>

| Topic | Video (YouTube) | Video (Courses) | Blog |
|-------|-----------------|-----------------|------|
| PyTorch | [Python Engineer](https://www.youtube.com/watch?v=EMXfZB8FVUA&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4), [Aladdin Persson](https://www.youtube.com/watch?v=2S1dgHpqCdk&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz) | [Udacity](https://www.udacity.com/course/deep-learning-nanodegree--nd101) with [github](https://github.com/udacity/deep-learning-v2-pytorch) repo for pytorch | [hsaghir](https://hsaghir.github.io/data_science/pytorch_starter/), [Kaggle](https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers), [Kaggle](https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners) |
| Back propagation | | | [backprop.org](https://www.backprop.org/) |
| Loss functions | [cross entropy](https://www.youtube.com/watch?v=sbvv-uQmwVY) | | [Kaggle](https://www.kaggle.com/avilay/pytorch-loss-functions-tutorial) |
| Optimizers | | | |
| Convolutional Neural Network | | | [Arxiv](https://arxiv.org/pdf/1603.07285.pdf) |
| Recurrent Neural Network | | | [LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) |
|Attention Mechanism | [CS7015](https://youtu.be/yInilk6x-OY), [CS480/680](https://youtu.be/OyFJWRnt_AY) | | [Tomek Korbak](https://tomekkorbak.com/2020/06/26/implementing-attention-in-pytorch/), [Jalammar](http://jalammar.github.io/illustrated-transformer/) |
| Seq to seq models | | | |
| Generative models | [GANs](https://www.youtube.com/playlist?list=PLhhyoLH6IjfwIp8bZnzX8QR30TRcHO8Va) | | |
| Graph Convolution Network | [Ahlad Kumar](https://youtube.com/playlist?list=PLdxQ7SoCLQANc6Q5HrKjALjjLD42IPRi-) | | [Medium](https://towardsdatascience.com/understanding-graph-convolutional-networks-for-node-classification-a2bfdb7aba7b), [Attention In Graph](https://towardsdatascience.com/graph-attention-networks-under-the-hood-3bd70dc7a87) |

#### Discussions : [pytorch forum](https://discuss.pytorch.org/), [stackoverflow](https://stackoverflow.com/)

#### Good Hands on tutorials: [Ben Trevett's Colab Notebooks](https://github.com/bentrevett)

#### Other helpful topics explained:
- `dim` parameter in `torch.tensor` [:notebook:](https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be)
- Matrix calculations in forward propagation of neural network: [:notebook:](https://medium.com/analytics-vidhya/mathematics-and-vectorization-behind-neural-network-b6d491fa617d)
- [BatchNormalization](https://www.youtube.com/watch?v=DtEq44FTPM4) intuition for training models
- [Regularisation](https://youtu.be/iuJgyiS7BKM) basic overview.
- All about object detection [:movie_camera:](https://www.youtube.com/playlist?list=PLog3nOPCjKBneGyffEktlXXMfv1OtKmCs), [:movie_camera:](https://www.youtube.com/playlist?list=PL1GQaVhO4f_jLxOokW7CS5kY_J1t1T17S), [:notebook:](https://d2l.ai/chapter_computer-vision/rcnn.html)
- Fine tuning faster-rcnn in PyTorch [Kaggle Notebook](https://www.kaggle.com/yerramvarun/fine-tuning-faster-rcnn-using-pytorch)
- TorchText ([video](https://www.youtube.com/watch?v=KRgq4VnCr7I), [blog](https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/)) for dealing with text data in NLP. Demo with [glove](https://www.cs.toronto.edu/~lczhang/360/lec/w06/w2v.html)

